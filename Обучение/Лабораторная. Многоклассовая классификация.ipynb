{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNLvinzjB1yYndVQyCCLPMn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Многоклассовая классификация"],"metadata":{"id":"iML2vHX-igvi"}},{"cell_type":"markdown","source":["Многие задачи классификации можно определить с использованием двух классов, но некоторые определены с использованием большего количества классов, что требует адаптации алгоритмов машинного обучения.\n","\n","![img](https://drive.google.com/uc?id=1Ky4HuMEKlwoUqBx2T6y6bajBHDX-gcBQ)"],"metadata":{"id":"MQL2MeyAikhb"}},{"cell_type":"markdown","source":["Логистическую регрессию можно естественным образом распространить на задачи многоклассового обучения, заменив сигмоидную функцию функцией `softmax`.\n","\n","Алгоритм kNN тоже легко распространить на случай многоклассовой классификации: отыскав k-ближайших данных для входа x, нужно вернуть класс, которому принадлежит больше всего данных среди k.\n","\n","Алгоритм SVM не получится естественным образом распространить на задачи многоклассовой классификации. Другие алгоритмы работают намного эффективнее, когда определены для двух классов. Что делать, если требуется решить задачу много- классовой классификации, но алгоритм обучения поддерживает только бинарную классификацию? В таких случаях часто используется стратегия, которая называется\n","\n","**«один против всех»**. Идея состоит в том, чтобы преобразовать задачу многоклассовой классификации в C задач бинарной классификации и построить C бинарных классификаторов. Например, если есть три класса  , нужно создать копии исходных наборов данных и модифицировать их. В первой копии заменить на 0 все метки, не равные 1. Во второй копии заменить на 0 все метки, не равные 2. В третьей копии заменить на 0 все метки, не равные 3. После этого останется только решить три задачи бинарной классификации и обучить модели различать метки 1 и 0, 2 и 0 и 3 и 0.\n","\n","После получения трех моделей для классификации нового входного вектора x, они применяются к входным данным и дают три прогноза. После этого остается только выбрать прогноз принадлежности к ненулевому классу, который является наиболее достоверным. \n","\n","В библиотеке `sklearn` рассматриваются два модуля: `sklearn.multiclass` и `sklearn.multioutput`. В приведенной ниже таблице показаны типы проблем, за которые отвечает каждый модуль, и соответствующие мета-оценки, которые предоставляет каждый модуль.\n","\n","![img](https://drive.google.com/uc?id=1PVN3TQRzRF6JpDX2M6ierwtwRibMhS_u)\n","\n","![img](https://drive.google.com/uc?id=1mn6QOwbbRLL5gz5hoGNehdidcnE4TQg5)\n","\n","\n","Хотя все классификаторы `scikit-learn` способны к многоклассовой классификации, предлагаемые мета-оценки `sklearn.multiclass` позволяют изменять способ обработки более двух классов, потому что это может повлиять на производительность классификатора (либо с точки зрения ошибки обобщения, либо с точки зрения требуемых вычислительных ресурсов)."],"metadata":{"id":"gG4JVuWTi6wB"}},{"cell_type":"markdown","source":["## Мультиклассовая классификация\n","Мультиклассовая классификация — это задача классификации с более чем двумя классами. Каждый образец можно пометить только как один класс. Например, классификация с использованием признаков, извлеченных из набора изображений фруктов, где каждое изображение может быть апельсином, яблоком или грушей. Каждое изображение представляет собой один образец и помечен как один из 3 возможных классов.\n","\n","## Один-против-остальных (one-vs-rest) \n","\n","стратегии, также известный как один-против-всех, реализуется `OneVsRestClassifier`. Стратегия заключается в подборе одного классификатора на класс. Для каждого классификатора класс сопоставляется со всеми другими классами. Помимо вычислительной эффективности (n_classes нужны только классификаторы), одним из преимуществ этого подхода является его интерпретируемость. Поскольку каждый класс представлен одним и только одним классификатором, можно получить информацию о классе, проверив соответствующий классификатор. Это наиболее часто используемая стратегия и справедливый выбор по умолчанию.\n"],"metadata":{"id":"YlWmIzZhjvlX"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnhq803_iW92","executionInfo":{"status":"ok","timestamp":1667901739192,"user_tz":-180,"elapsed":1484,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"a22afdfa-10ea-4a46-9611-abf4b9d40ec2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n","       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":1}],"source":["from sklearn import datasets\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.svm import LinearSVC\n","X, y = datasets.load_iris(return_X_y=True)\n","OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)\n"]},{"cell_type":"markdown","source":["## OneVsOneClassifier \n","создает один классификатор на пару классов. Во время прогнозирования выбирается класс, получивший наибольшее количество голосов. В случае равенства голосов (среди двух классов с равным количеством голосов) он выбирает класс с наивысшей совокупной достоверностью классификации путем суммирования уровней достоверности попарной классификации, вычисленных базовыми двоичными классификаторами.\n","Поскольку он требует соответствия `n_classes * (n_classes — 1) / 2` классификаторам, этот метод обычно медленнее, чем метод «один против остальных» из-за его сложности `O (n_classes ^ 2)`.\n"],"metadata":{"id":"La64xKe-kP3_"}},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.multiclass import OneVsOneClassifier\n","from sklearn.svm import LinearSVC\n","X, y = datasets.load_iris(return_X_y=True)\n","OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_xYg8Jukc1e","executionInfo":{"status":"ok","timestamp":1660635175977,"user_tz":-180,"elapsed":296,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"00f48332-64fa-46fe-b2e2-0e32d02b3023"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## OutputCodeClassifier \n","стратегия на основе выходного кода с исправлением ошибок сильно отличаются от стратегий «один против остальных» и «один против одного». С помощью этих стратегий каждый класс представлен в евклидовом пространстве, где каждое измерение может быть только 0 или 1. Другими словами, каждый класс представлен двоичным кодом (массивом из 0 и 1). Матрица, которая отслеживает местоположение / код каждого класса, называется кодовой книгой. Размер кода — это размерность вышеупомянутого пространства. Интуитивно каждый класс должен быть представлен как можно более уникальным кодом, и должна быть разработана хорошая кодовая книга для оптимизации точности классификации. В этой реализации просто используем случайно сгенерированную кодовую книгу. Во время подгонки устанавливается один двоичный классификатор на бит в кодовой книге. Во время прогнозирования классификаторы используются для проецирования новых точек в пространстве классов, и выбирается класс, ближайший к этим точкам."],"metadata":{"id":"MPtjyBa4kgWi"}},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.multiclass import OutputCodeClassifier\n","from sklearn.svm import LinearSVC\n","X, y = datasets.load_iris(return_X_y=True)\n","clf = OutputCodeClassifier(LinearSVC(random_state=0), code_size=2, random_state=0)\n","clf.fit(X, y).predict(X)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CGmWjyWkj2Y","executionInfo":{"status":"ok","timestamp":1660635218763,"user_tz":-180,"elapsed":307,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"68456625-7095-4086-dee5-b920bb6d92d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n","       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Классификация по нескольким меткам\n","Классификация с несколькими метками (тесно связана с классификацией с несколькими выходами) — это задача классификации, при которой каждый образец m маркируется метками из `n_classes` возможных классов, где m может быть от 0 до `n_classes` включительно. Это можно рассматривать как прогнозирование свойств образца, которые не исключают друг друга. Формально двоичный вывод назначается каждому классу для каждой выборки. Положительные классы обозначаются цифрой 1, а отрицательные классы — 0 или -1. Этот подход обрабатывает каждую метку независимо, тогда как классификаторы с несколькими метками могут обрабатывать несколько классов одновременно, учитывая коррелированное поведение между ними.\n","\n","Например, предсказание тем, относящихся к текстовому документу или видео. Документ или видео могут быть посвящены одному из следующих: «религия», «политика», «финансы» или «образование», несколько тематических классов или все тематические классы.\n","\n","Поддержка классификации с несколькими метками может быть добавлена к любому классификатору с помощью `MultiOutputClassifier`. Эта стратегия состоит из подбора одного классификатора для каждой цели. Цель этого класса — расширить оценщики, чтобы иметь возможность оценивать серию целевых функций `(f1, f2, f3…, fn)`, которые обучены на одной матрице предикторов X, чтобы предсказать серию ответов `(y1, y2, y3 …, Уn)`.\n","Ниже приведен пример классификации по множеству ярлыков:\n"],"metadata":{"id":"7NfSvtaSkphw"}},{"cell_type":"code","source":["from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","# создаем битовую маску\n","y = label_binarize(y, classes=[0,1,2  ])\n","n_classes = y.shape[1]\n","# разбиваем на обучающую и тестовую\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","# Это простая стратегия расширения классификаторов, которые изначально не поддерживают многоцелевую классификацию (например Логистическая регрессия)\n","classifier = MultiOutputClassifier(LogisticRegression()).fit(X_train, y_train)\n","pred=classifier.predict(X_test)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjEtZtSVk47e","executionInfo":{"status":"ok","timestamp":1667901762524,"user_tz":-180,"elapsed":646,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"83e4cabb-4048-4464-c33b-bcc722285be7"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 1],\n","       [0, 1, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [1, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [0, 1, 1],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [0, 0, 1],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 1, 0],\n","       [0, 0, 1],\n","       [0, 0, 1],\n","       [0, 1, 0],\n","       [0, 1, 1],\n","       [0, 1, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [0, 0, 1],\n","       [0, 0, 1],\n","       [0, 1, 0],\n","       [0, 1, 1],\n","       [0, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [0, 0, 0],\n","       [0, 1, 0],\n","       [0, 0, 0],\n","       [0, 0, 1],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 1],\n","       [0, 0, 0],\n","       [1, 0, 0],\n","       [1, 0, 0],\n","       [0, 0, 0]])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## Цепочки классификаторов (ClassifierChain) \n","это способ объединения ряда бинарных классификаторов в единую модель с несколькими метками, которая способна использовать корреляции между целями.\n","\n","Для задачи классификации с несколькими метками с N классами N двоичным классификаторам присваивается целое число от 0 до N-1. Эти целые числа определяют порядок моделей в цепочке. Затем каждый классификатор соответствует доступным обучающим данным плюс истинным меткам классов, моделям которых был присвоен меньший номер.\n","\n","При прогнозировании истинные метки будут недоступны. Вместо этого прогнозы каждой модели передаются последующим моделям в цепочке. Ясно, что порядок цепочки важен. Первая модель в цепочке не имеет информации о других метках, в то время как последняя модель в цепочке имеет признаки, указывающие на наличие всех других меток. Как правило, неизвестен оптимальный порядок моделей в цепочке, поэтому обычно подбирается много случайно упорядоченных цепочек, а их прогнозы усредняются вместе.\n"],"metadata":{"id":"1DWdo-QZlDxQ"}},{"cell_type":"code","source":["from sklearn.multioutput import ClassifierChain\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","# создаем битовую маску\n","y = label_binarize(y, classes=[0,1,2  ])\n","n_classes = y.shape[1]\n","# разбиваем на обучающую и тестовую\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n","base_lr = LogisticRegression(solver='lbfgs', random_state=0)\n","chain = ClassifierChain(base_lr, order='random', random_state=0)\n","pred=chain.fit(X_train, y_train).predict(X_test)\n","pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEZ6PKvClLh4","executionInfo":{"status":"ok","timestamp":1660635373166,"user_tz":-180,"elapsed":320,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"b1798d0f-fa37-4be1-e3d5-189d5ccdc416"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.]])"]},"metadata":{},"execution_count":7}]}]}