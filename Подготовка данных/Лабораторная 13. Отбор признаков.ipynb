{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAeMVJskWmwGJ8FQ1HfDi2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!git clone https://github.com/stuniy/SPO_PGU.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqL93jBrCAf8","executionInfo":{"status":"ok","timestamp":1690537362755,"user_tz":-180,"elapsed":25199,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"34b951ea-d22d-4723-ca85-d1b9bff1d188"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'SPO_PGU'...\n","remote: Enumerating objects: 159, done.\u001b[K\n","remote: Counting objects: 100% (90/90), done.\u001b[K\n","remote: Compressing objects: 100% (80/80), done.\u001b[K\n","remote: Total 159 (delta 23), reused 46 (delta 10), pack-reused 69\u001b[K\n","Receiving objects: 100% (159/159), 74.78 MiB | 6.88 MiB/s, done.\n","Resolving deltas: 100% (44/44), done.\n","Updating files: 100% (53/53), done.\n"]}]},{"cell_type":"markdown","source":["# Отбор признаков"],"metadata":{"id":"LbS_Na2eBNYQ"}},{"cell_type":"markdown","source":["**Отбор признаков** – это отбор подмножества важных признаков для последующего построения модели машинного обучения.\n","\n","Почему отбор фич (признаков) вообще необходим. Основных причин две.\n","- во-первых, если фич очень много, то увеличивается время работы классификатора. Если стоит цель протестировать несколько классификаторов с целью выбора лучшего, то время необходимое на вычисления может стать просто огромным.\n","- кроме того, данные (тренировочный сет) могут перестать помещаться в оперативную память, тогда придется модифицировать алгоритмы классификаторов. Может перестать помещаться даже одна строка сета, хотя это уже редкий случай.\n","- улучшение обобщающей способности модели из-за уменьшения проклятия размерности и переобучения\n","(удаление избыточных и нерелевантных переменных делает модель менее сложной и менее восприим-\n","чивой к случайным возмущениям обучающих данных, которые сложной моделью будут восприняты за\n","сигнал);\n","- сокращение времени обучения;\n","- простые модели легче интерпретировать;\n","- простые модели легче имплементировать.\n","\n","Главная причина все-таки вторая — с увеличением количества фич часто падает точность предсказания. Особенно если в данных много мусорных фич (мало коррелирующих с целевой переменной). Это явление называется переобучение (`overfitting`).\n","\n","Обычно выделяют задачу-минимум и задачу-максимум.\n","- Задача-минимум – сократить признаковое пространство без потери качества.\n","- Задача-максимум – сократить признаковое пространство и при этом улучшить качество модели.\n","\n"],"metadata":{"id":"Asty1nATBRZ_"}},{"cell_type":"markdown","source":["Как правило, методы отбора признаков характеризуются высокими вычислительными затратами, один и\n","тот же метод отбора признаков для разных методов машинного обучения может дать разные подмножества\n","признаков. Не существует одного оптимального метода отбора признаков. Вопрос «какой метод отбора\n","признаков является лучшим?» тождествен вопросу «какой метод машинного обучения является лучшим?».\n","Поэтому каждый раз берем задачу и пробуем разные методы отбора признаков. Важный признак является\n","реле- вантным (связан с зависимой переменной) и неизбыточным (дает новую информацию, еще не объясненную другими признаками).\n","\n","Методы отбора фич делятся на три категории:\n","\n","•\tметоды фильтрации (filter methods);\n","\n","•\tметоды \"обёртки\" (wrapper methods);\n","\n","•\tвстроенные методы (embedded methods);\n","\n","•\tотбор с использованием моделей.\n","\n","Кроме того, можно выделить гибридные подходы, сочетающие методы- обертки и встроенные методы.\n","Кстати, именно они на практике часто дают наилучшие результаты.\n"],"metadata":{"id":"8PyapDJ5myII"}},{"cell_type":"markdown","source":["## Методы фильтрации (filter methods).\n","\n","Они основаны на статистических методах и, как правило, рассматривают каждую фичу независимо. Позволяют оценить и ранжировать фичи по значимости, за которую принимается степень корреляции этой фичи с целевой переменной. Рассмотрим несколько примеров.\n","\n","В их основе – следующая процедура:\n","\n","- получаем оценку каждого признака по отдельности с точки зрения определенного критерия (например, с точки зрения IV), таким образом, отбор является одномерным;\n","- ранжируем признаки по полученным оценкам;\n","- выбираем признаки с наиболее высокой оценкой.\n","\n","\n"],"metadata":{"id":"Tt_ShQHtBiRi"}},{"cell_type":"markdown","source":["Методы-фильтры не годятся для отбора сильных переменных. Они могут отбирать избыточные переменные, поскольку преимущественно являются одномерными и не учитывают взаимосвязи между признаками (за исключением методов-фильтров на основе корреляции). Мы оцениваем, как признак работает сам по себе, а не в сочетании с другими признаками. Методы-фильтры хороши для быстрого мониторинга и удаления наименее релевантных признаков (константных, дублирующихся признаков) на самом раннем этапе отбора признаков.\n","Примерами методов-фильтров может быть отбор признаков по:\n","- информационному значению (чем выше значение IV, тем выше прогнозная сила);\n","- взаимной информации (насколько информация, содержащаяся в признаке, снижает неопределенность\n","относительно зависимой переменной; если признак и целевая переменная не зависят друг от друга, взаимная информация равна 0);\n","- дисперсии (низкая оценка дисперсии может указывать на почти константный признак);\n","- критерию хи-квадрат или F-критерию (чем выше значение хи-квадрат/ F-критерий и ниже p-значение,\n","тем переменная важнее);\n","- коэффициенту корреляции (есть корреляция с зависимой переменной – хороший признак, есть корреляция с другим признаком – избыточный признак);\n","- метрике (чем выше AUC, тем важнее признак).\n"],"metadata":{"id":"UHYfpuG6vTb1"}},{"cell_type":"markdown","source":["## Сбор информации (Information Gain, IG).\n","\n","Вычисляет уменьшение энтропии в результате преобразования набора данных. Его можно использовать для отбора признаков путем оценки информационного прироста каждой переменной в контексте целевой переменной.\n","\n","![img](https://drive.google.com/uc?id=1mSj8MX3Ytptr77vNyOAiCgVcW67y2Hzt)"],"metadata":{"id":"ryJn_Bglu2yt"}},{"cell_type":"markdown","source":["Чтобы лучше понять смысл этой меры, можно представить два простых примера.\n","\n","Во-первых, подбрасывание монетки, у которой выпадение орла и решки равновероятны. В этом случае энтропия, рассчитанная по формуле, будет равна 1. Если же монета всегда падает исключительно орлом вверх, то энтропия будет равна 0. Иными словами высокая энтропия говорит о равномерном распределении, низкая — о каком-то более интересном."],"metadata":{"id":"BCv98U-zCFcm"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","data=pd.read_csv('/content/SPO_PGU/diabetes.csv')\n","X=data.iloc[:,:7]\n","y=data.iloc[:,8]\n","X,y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTe9UmPhC0Ro","executionInfo":{"status":"ok","timestamp":1690537417186,"user_tz":-180,"elapsed":666,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"7879f0e3-dc53-4d15-a3a4-9f5360e52e7f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n"," 0              6      148             72             35        0  33.6   \n"," 1              1       85             66             29        0  26.6   \n"," 2              8      183             64              0        0  23.3   \n"," 3              1       89             66             23       94  28.1   \n"," 4              0      137             40             35      168  43.1   \n"," ..           ...      ...            ...            ...      ...   ...   \n"," 763           10      101             76             48      180  32.9   \n"," 764            2      122             70             27        0  36.8   \n"," 765            5      121             72             23      112  26.2   \n"," 766            1      126             60              0        0  30.1   \n"," 767            1       93             70             31        0  30.4   \n"," \n","      DiabetesPedigreeFunction  \n"," 0                       0.627  \n"," 1                       0.351  \n"," 2                       0.672  \n"," 3                       0.167  \n"," 4                       2.288  \n"," ..                        ...  \n"," 763                     0.171  \n"," 764                     0.340  \n"," 765                     0.245  \n"," 766                     0.349  \n"," 767                     0.315  \n"," \n"," [768 rows x 7 columns],\n"," 0      1\n"," 1      0\n"," 2      1\n"," 3      0\n"," 4      1\n","       ..\n"," 763    0\n"," 764    0\n"," 765    0\n"," 766    1\n"," 767    0\n"," Name: Outcome, Length: 768, dtype: int64)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.feature_selection import mutual_info_classif\n","\n","importances = mutual_info_classif(X, y)\n","feature_importances = pd.Series(importances,X.columns)\n","feature_importances.plot(kind='barh', color='teal')\n","plt.show()\n","feature_importances.sort_values(ascending=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":569},"id":"4M6iG2icGHbe","executionInfo":{"status":"ok","timestamp":1690456015270,"user_tz":-180,"elapsed":677,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"fd1a7bc2-095b-4c59-ab62-8ea76245a788"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Glucose                     0.132685\n","BMI                         0.100459\n","Pregnancies                 0.054788\n","Insulin                     0.044996\n","BloodPressure               0.037206\n","DiabetesPedigreeFunction    0.013530\n","SkinThickness               0.003898\n","dtype: float64"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Критерий хи-квадрат (Chi-square Test)\n","\n","Взаимная информация измеряет взаимную зависимость двух переменных X и Y. Другими словами, она определяет, насколько точно мы можем определить переменную Y, зная переменную X. Здесь нас интересует, насколько совместное распределение P(X,Y) похоже на произведение маргинальных распределений P(X)P(Y). Если X и Y независимы, то взаимная информация будет равна нулю.\n","\n","Используется для категориальных признаков в датасете. Мы вычисляем хи-квадрат между каждым признаком и целью, после выбираем желаемое количество “фич” с лучшими показателями. Чтобы правильно применить критерий для проверки связи между различными функциями в наборе данных и целевой переменной, должны быть выполнены следующие условия: категориальные переменные, которые выбираются независимо, и частота значений > 5.\n","\n","Тест Хи-квадрат предполагает нулевую гипотезу о том, что две переменные независимы, и альтернативную гипотезу о том, что две переменные зависимы, как и большинство других статистических тестов. Используя критерий хи-квадрат, он вычисляет p-значения каждого объекта относительно целевого объекта. Проще говоря, p - это вероятность того, что две переменные независимы. Наша цель состоит в том, чтобы определить функции, которые зависят от цели, другими словами, отвергая нулевую гипотезу. По этой причине мы выбираем объекты, у которых обычно значение p меньше 0,05. Пороговое значение 0.05 - это просто обычное поведение, вы можете установить меньшие пороговые значения, например 0.01, чтобы быть более уверенным в том, что две группы зависят друг от друга.\n","\n","И  критерий  хи-квадрат,  и  критерий  Фишера  из-за  использования p-значений чувствительны к размеру выборки, поэтому на больших выборках большинство признаков будут значимыми. Вы должны помнить, что низкое p-значение может указывать не на высокую прогнозную силу переменной, а просто на тот факт, что мы работаем с большим набором данных. Поэтому полезнее смотреть не на сами\n","p-значения, а сравнивать эти p-значения между собой.\n","\n","\n"],"metadata":{"id":"ItqWlATBCZK7"}},{"cell_type":"code","source":["# примените класс SelectKBest, чтобы извлечь лучшие показатели\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","\n","bestfeatures = SelectKBest(score_func=chi2, k='all')\n","fit = bestfeatures.fit(X,y)\n","dfscores = pd.DataFrame(fit.scores_)\n","dfcolumns = pd.DataFrame(X.columns)\n","\n","#объединим два фрейма данных для лучшей визуализации\n","featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n","featureScores.columns = ['Specs','Score']  #название показателей\n","print(featureScores.nlargest(11,'Score'))\n","\n","feature_importances = pd.Series(featureScores['Score'])\n","feature_importances.plot(kind='barh', color='teal')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":569},"id":"CQE5bZuyH792","executionInfo":{"status":"ok","timestamp":1690456423339,"user_tz":-180,"elapsed":820,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"9cb3b666-0549-41b0-a630-5c838309d095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                      Specs        Score\n","4                   Insulin  2175.565273\n","1                   Glucose  1411.887041\n","5                       BMI   127.669343\n","0               Pregnancies   111.519691\n","3             SkinThickness    53.108040\n","2             BloodPressure    17.605373\n","6  DiabetesPedigreeFunction     5.392682\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","\n","# разбиваем набор данных на обучающую и тестовую выборки\n","X_train, X_test, y_train, y_test = train_test_split(data.drop('Outcome', axis=1),data['Outcome'],test_size=0.3,random_state=42)\n","\n","# создаем список признаков\n","col_list = X_train.select_dtypes(include=['number']).columns\n","print(col_list)\n","print(X_train.shape, y_train.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-xGIYYNHNS3","executionInfo":{"status":"ok","timestamp":1690457552568,"user_tz":-180,"elapsed":252,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"37c6741a-f3a6-40d9-ef83-faa44da586c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n","       'BMI', 'DiabetesPedigreeFunction', 'Age'],\n","      dtype='object')\n","(537, 8) (537,)\n"]}]},{"cell_type":"code","source":["# вычисляем AUC для модели с одним признаком,\n","# используя перекрестную проверку\n","log = LogisticRegression(solver='liblinear')\n","auc=cross_val_score(log, X_train, y_train, cv=5, scoring='roc_auc')\n","\n","# превращаем список со значениями AUC в серию\n","auc_values = pd.Series(auc)\n","print(auc_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30SWu6lFHhmc","executionInfo":{"status":"ok","timestamp":1690458104540,"user_tz":-180,"elapsed":236,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"fbb0fa2d-0dbc-4784-da2a-4667124d41cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0    0.860902\n","1    0.792105\n","2    0.876834\n","3    0.780309\n","4    0.835240\n","dtype: float64\n"]}]},{"cell_type":"code","source":["# сортируем по убыванию\n","auc_values = auc_values.sort_values(ascending=False)\n","auc_values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZfUAB5OD2tR","executionInfo":{"status":"ok","timestamp":1690457997441,"user_tz":-180,"elapsed":287,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"e0b93155-5115-47ed-db6d-327fc857a308"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    0.876834\n","0    0.860902\n","4    0.835240\n","1    0.792105\n","3    0.780309\n","dtype: float64"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# формитруем датасет только из информативных показателей\n","x_1=X.iloc[:,auc_values.index]#3\n","x_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"2sBVsaQiK21e","executionInfo":{"status":"ok","timestamp":1690458512948,"user_tz":-180,"elapsed":268,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"b52c9935-7810-4007-9fb0-73f03c6b077f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin\n","0              6      148             72             35        0\n","1              1       85             66             29        0\n","2              8      183             64              0        0\n","3              1       89             66             23       94\n","4              0      137             40             35      168\n","..           ...      ...            ...            ...      ...\n","763           10      101             76             48      180\n","764            2      122             70             27        0\n","765            5      121             72             23      112\n","766            1      126             60              0        0\n","767            1       93             70             31        0\n","\n","[768 rows x 5 columns]"],"text/html":["\n","\n","  <div id=\"df-dd55df2e-614d-45d6-812e-e39d83836ca1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10</td>\n","      <td>101</td>\n","      <td>76</td>\n","      <td>48</td>\n","      <td>180</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2</td>\n","      <td>122</td>\n","      <td>70</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5</td>\n","      <td>121</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>112</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1</td>\n","      <td>126</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1</td>\n","      <td>93</td>\n","      <td>70</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd55df2e-614d-45d6-812e-e39d83836ca1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-4a8d4895-db54-451e-9a6b-18fdf35ca142\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a8d4895-db54-451e-9a6b-18fdf35ca142')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-4a8d4895-db54-451e-9a6b-18fdf35ca142 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd55df2e-614d-45d6-812e-e39d83836ca1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd55df2e-614d-45d6-812e-e39d83836ca1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["## Плюсы и минусы методов фильтрации.\n","Чем этот класс методов хорош? У них низкая стоимость вычислений, которая зависит линейно от общего количества фич. Они значительно быстрее и wrapper и embedded методов. К тому же они хорошо работают даже тогда, когда число фич у нас превышает количество примеров в тренировочном сете (чем далеко не всегда могут похвастаться методы других категорий).\n","\n","В чем их недостатки? Они рассматривают каждую фичу изолированно. Из-за этого найти топ-N наиболее коррелирующих фич вообще говоря не означает получить подмножество, на котором точность предсказания будет наивысшей.\n"],"metadata":{"id":"UT-g6uY_Ldia"}},{"cell_type":"markdown","source":["## Методы обертки.\n","Суть этой категории методов в том, что классификатор запускается на разных подмножествах фич исходного тренировочного сета. После чего выбирается подмножество фич с наилучшими параметрами на обучающей выборке. А затем он тестируется на тестовом сете (тестовый сет не участвует в процессе выбора оптимального подмножества).\n","\n","Методы-обертки используют методы машинного обучения, таким образом, зависят от моделей машинного\n","обучения. В их основе – следующая процедура:\n","- находим подмножество признаков;\n","- строим модель машинного обучения на этом подмножестве признаков;\n","- оцениваем качество модели;\n","- повторяем.\n","\n","\n","Есть два подхода в этом классе методов — методы включения (`forward selection`) и исключения (`backwards selection`) фич. Первые стартуют с пустого подмножества, куда постепенно добавляются разные фичи (для выбора на каждом шаге оптимального добавления). Во втором случае метод стартует с подмножества равного исходному множеству фич, и из него постепенно удаляются фичи, с пересчетом классификатора каждый раз.\n","\n","## Прямой отбор признаков.\n","Это крайне прямолинейный метод, в котором мы начинаем с наиболее эффективной переменной по отношению к цели. Затем мы выбираем другую переменную, которая дает лучшую производительность в сочетании с первой. Этот процесс продолжается до тех пор, пока не будет достигнут заданный критерий.\n"],"metadata":{"id":"zD0K6yW5MyGE"}},{"cell_type":"code","source":["pip install mlxtend"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnTJwijQNY76","executionInfo":{"status":"ok","timestamp":1690458675032,"user_tz":-180,"elapsed":6645,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"1f3f60e9-3e2a-4c25-c166-715324ad96af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.10.1)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.22.4)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.5.3)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.2.2)\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (3.7.1)\n","Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.3.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend) (67.7.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["## Рекурсивное исключение признаков.\n","\n","Сначала модель обучается на начальной выборке признаков, и важность каждой функции определяется либо с помощью атрибута `coef_` или `feature_importances_`. Затем наименее важные “фичи” удаляются из текущего набора. Процедура рекурсивно повторяется для сокращенного набора до тех пор, пока в конечном итоге не будет достигнуто желаемое количество признаков для выбора."],"metadata":{"id":"5FVY98wVNvae"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import RFE\n","\n","threshold = 5 # the number of most relevant features\n","\n","lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=42, n_jobs=-1, max_iter=50)\n","\n","rfe = RFE(lr, n_features_to_select=5)\n","rfe=rfe.fit(X, y)\n","# X_train, y_train - входные и выходные данные с обучающей выборки соответственно.\n","selector_ind = rfe.get_support()\n","df_rfe = X.iloc[:, selector_ind]\n","print(df_rfe.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsxVyqMcN7nv","executionInfo":{"status":"ok","timestamp":1690458742118,"user_tz":-180,"elapsed":253,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"4a200e89-ce99-4eb8-a235-cb751783ed8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Pregnancies', 'Glucose', 'BloodPressure', 'BMI',\n","       'DiabetesPedigreeFunction'],\n","      dtype='object')\n"]}]},{"cell_type":"markdown","source":["Вместе с тем методы-обертки, в отличие от методов-фильтров, чаще позволяют найти подмножество\n","признаков, дающее наилучшее качество модели. Это обусловлено тем, что в отличие от методов-фильтров\n","они могут учитывать взаимодействия переменных. Вы должны помнить, что некоторые признаки могут не обладать прогнозной силой по отдельности, но в сочетании с другими переменными приобретают ее.\n","\n","Разумеется, с помощью метода-обертки мы не можем получить подмножество признаков, которое даст наилучшее качество при использовании разных моделей машинного обучения.\n","\n","*Например, подмножество признаков, найденное с помощью логистической регрессии, не гарантирует наилучшего качества при построении градиентного бустинга на этом подмножестве. В то же время подмножество признаков,\n","отобранное с помощью градиентного бустинга, может дать хорошее качество при построении на этом подмножеств случайного леса. Поэтому, выбирая метод-обертку, нужно помнить о том, какую модель машинного обучения мы потом будем строить на отобранном подмножестве признаков.*\n"],"metadata":{"id":"OXVX1ODp0Yej"}},{"cell_type":"markdown","source":["## Встроенные методы (`embedded methods`).\n","Эти методы включают в себя преимущества первых двух, а также уменьшают вычислительные затраты. Отличительной особенностью встроенных методов является извлечение “фич” на этапе конкретной итерации.\n","\n","Встроенные методы выполняют отбор признаков в ходе обучения модели машинного обучения. В их основе – следующая процедура:\n","- обучаем модель машинного обучения;\n","- вычисляем важности признаков;\n","- удаляем неважные признаки (в случайном лесе или бустинге для этого задается определенный порог, ниже которого считаем признаки неважными, в методе LASSO неважные признаки просто получат нулевые коэффициенты и будут исключены из модели).\n","\n","\n"],"metadata":{"id":"JgiFZLlHocwT"}},{"cell_type":"markdown","source":["Основным методом из этой категории является регуляризация. Существуют различные ее разновидности, но основной принцип общий. Если рассмотреть работу классификатора без регуляризации, то она состоит в построении такой модели, которая наилучшим образом настроилась бы на предсказание всех точек тренировочного сета.\n","\n","Например, если алгоритм классификации линейная регрессия, то подбираются коэффициенты полинома, который аппроксимирует зависимость между фичами и целевой переменной. В качестве оценки качества подобранных коэффициентов выступает среднеквадратичная ошибка (`RMSE`). Т.е. параметры подбираются так, чтобы суммарное отклонение (точнее суммарный квадрат отклонений) у точек, предсказанных классификатором от реальных точек, было минимальным.\n","Идея регуляризации в том, чтобы построить алгоритм минимизирующий не только ошибку, но и количество используемых переменных.\n","\n"],"metadata":{"id":"b_7wBtFg1UJc"}},{"cell_type":"markdown","source":["## Регуляризация LASSO (L1).\n","Регуляризация состоит в добавлении штрафа (penalty) к различным параметрам модели во избежание чрезмерной подгонки. При регуляризации линейной модели штраф применяется к коэффициентам, умножающим каждый из предикторов. Lasso-регуляризация обладает свойством, позволяющим уменьшить некоторые коэффициенты до нуля. Следовательно, такие “фичи” можно будет просто удалить из модели.\n","\n","![img](https://drive.google.com/uc?id=1pAFQRa8I_-twxgh_2qbkrjJHoezkrY7i)"],"metadata":{"id":"fMpN4L1F1XbN"}},{"cell_type":"markdown","source":["В процессе работы алгоритма размеры коэффициентов будут пропорциональны важности соответствующих переменных, а перед теми переменными, которые дают наименьший вклад в устранение ошибки, станут околонулевые. В LASSO с ростом альфа все больше коэффициентов становятся нулевыми и совсем перестают вносить вклад в модель. Таким образом, мы получаем действительно отбор фич. Более значимые фичи сохранят свои коэффициенты ненулевыми, менее значимые — обнулятся."],"metadata":{"id":"874lL_ETpXl2"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import SelectFromModel\n","\n","# Устанавливаем наш параметр регуляризации C=1\n","logistic = LogisticRegression(C=1, penalty=\"l1\", solver='liblinear', random_state=7).fit(X, y)\n","# Где X, y - входные и выходные данные соответственно.\n","model = SelectFromModel(logistic, prefit=True)\n","\n","X_new = model.transform(X)\n","\n","# выводим финальную оценку прогнозирования.\n","selector_ind = model.get_support()\n","df_rfe1 = X.iloc[:, selector_ind]\n","print(df_rfe1.columns)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBSuIVCBpiid","executionInfo":{"status":"ok","timestamp":1690458766870,"user_tz":-180,"elapsed":240,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"c3300c2c-e2d6-4f87-ced4-f9dc82278a8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n","       'BMI', 'DiabetesPedigreeFunction'],\n","      dtype='object')\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## Регуляризация Тихонова (L2).\n","\n","Суть в том, что чересчур тяжёлые весовые коэффициенты «отталкивают» нашу линию наилучшего соответствия, построенную на основе минимизации квадрата ошибок, от основной тендеции.\n","\n","![img](https://drive.google.com/uc?id=1_B9TGeTVXUK5F8iPnF1JJL-x1GSw7BXZ)\n","\n","Тут получается, что функция занижает пики прибавляя сумму весов в квадрате с множителем лямбда.\n","Происходит легкое смещение добавляя статистическую ошибку, которая не влияет на точность, но позволяет не переобучиться. Соответственно если вы поставите большую коэффициент (лямбда) L2, то система никогда не обучится, просто из-за того, что сильно сместиться. Но если лямбда будет маленькой, то и смещение будет маленьким, и весь смысл регуляризации так же будет минимальным.\n"],"metadata":{"id":"2evsMDc0rKp-"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","import numpy as np\n","n_samples, n_features = 10, 5\n","rng = np.random.RandomState(0)\n","y = rng.randn(n_samples)\n","X = rng.randn(n_samples, n_features)\n","clf = Ridge(alpha=1.0)\n","clf.fit(X, y)\n","clf.coef_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3EXQ1XcrsUY","executionInfo":{"status":"ok","timestamp":1660553267008,"user_tz":-180,"elapsed":299,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"4de30761-d130-4f92-d8d7-0725cf23cb19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.51088991,  0.03729032, -0.65075201,  0.0930311 ,  0.93380887])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Не стоит думать, что регуляризация бывает только в линейных моделях, и для бустинга и для нейросетей существуют свои методы регуляризации.\n","Из минусов регуляризации можно отметить тот факт, что модель строится на всем массиве фич а значит, она не ускоряет работу классификатора. Но в общем случае этот метод способен лучше уловить взаимозависимости переменных, чем методы фильтрации.\n","Как выбрать между двумя типами регуляризации?\n","•\tесли фичей очень много (сотни), среди которых есть потенциально не важные - выбирай L1\n","•\tфичей мало и все они важны - выбирай L2\n"],"metadata":{"id":"cTs7gIBSsDXM"}},{"cell_type":"markdown","source":["**Как видно из конечных наборов функций, мы получаем разные результаты для разных подходов, поэтому нет определенной истины в выборе функций.**\n","\n","Методы фильтрации часто являются одномерными и учитывают признаки независимо или с учетом зависимой переменной. Однако это не всегда правильное предположение. Иногда функция сама по себе не имеет смысла, в то время как она может улучшить модель с помощью комбинаций других функций. Таким образом, подобные ситуации упускаются из виду в методах фильтрации. Кроме того, оценка статистических измерений для выбора признаков не способствует производительности модели, поэтому может не повысить точность модели. С другой стороны, эти подходы просты и выгодны по сравнению с другими в отношении времени обучения.\n","\n","Методы-оболочки используют итеративные процедуры поиска и используются вместе с моделью. В отличие от методов фильтрации, он учитывает комбинации объектов и возвращает подмножество объектов. Это может быть реализовано жадным или нежадным способом. Жадные подходы, такие как RFE, могут столкнуться с такими проблемами, как попадание в ловушку локальных оптимумов. Как правило, они работают медленнее, чем методы фильтрации, поскольку требуют больших объемов вычислений с учетом итеративного подхода.\n","\n","Встроенные методы работают быстрее, чем методы-оболочки, поскольку процесс выбора встроен в процесс подгонки модели. Они также обеспечивают прямую связь между выбором функций и производительностью модели. Таким образом, вы можете получить более удовлетворительные результаты с помощью встроенных методов. Одним из недостатков этого подхода является то, что он зависит от модели. Данные могут лучше соответствовать модели, которая неудобна для встроенных видов выбора функций."],"metadata":{"id":"Vsn8ZX67sqfZ"}},{"cell_type":"markdown","source":["### Комбинирование несколькиХ методов для отбора признаков\n"],"metadata":{"id":"SA4zXYC6NY--"}},{"cell_type":"code","source":["pip install CatBoost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"karBw5riN3Ns","executionInfo":{"status":"ok","timestamp":1690537451728,"user_tz":-180,"elapsed":13832,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"0f177c2f-cb1d-4d46-85cf-81b5182b09b1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting CatBoost\n","  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from CatBoost) (0.20.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from CatBoost) (3.7.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.22.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.10.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from CatBoost) (5.13.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->CatBoost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->CatBoost) (2022.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (3.1.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->CatBoost) (8.2.2)\n","Installing collected packages: CatBoost\n","Successfully installed CatBoost-1.2\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import GridSearchCV\n","from catboost import CatBoostClassifier, Pool\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import (train_test_split,\n","                                     cross_val_score,\n","                                     cross_validate)\n","\n","# разбиваем набор данных на обучающую и тестовую выборки\n","X_train, X_test, y_train, y_test = train_test_split(data.drop('Outcome', axis=1),data['Outcome'],test_size=0.3,random_state=42)\n","\n","# Сначала ищем оптимальный темп обучения для зафиксированного количества деревьев\n","\n","# создаем экземляр класса LGBMClassifier\n","lgbm_model = LGBMClassifier(random_state=42,n_estimators=300)\n","# задаем сетку гиперпараметров\n","param_grid = {\n","              'learning_rate': [0.01, 0.05, 0.1]\n","              }\n","# создаем экземпляр класса GridSearchCV, передав\n","# конвейер, сетку гиперпараметров и указав\n","# количество блоков перекрестной проверки\n","gs = GridSearchCV(lgbm_model,param_grid, scoring='roc_auc', cv=5)\n","\n","# выполняем поиск по всем значениям сетки\n","gs.fit(X_train, y_train);\n","\n","# смотрим наилучшие значения гиперпараметров\n","print(\"Наилучшие значения гиперпараметров: {}\".format( gs.best_params_))\n","# смотрим наилучшее значение AUC\n","print(\"Наилучшее значение AUC: {:.3f}\".format(gs.best_score_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLAw34YUNgV7","executionInfo":{"status":"ok","timestamp":1690538060348,"user_tz":-180,"elapsed":2306,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"56c622c5-6dad-4498-84d8-44349746372b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Наилучшие значения гиперпараметров: {'learning_rate': 0.01}\n","Наилучшее значение AUC: 0.841\n"]}]},{"cell_type":"code","source":["# Теперь ищем с помощью обычного поиска по сетке оптимальные значения гиперпараметров\n","# Гиперпараметр lambda_l1 - задает штрафной коэффициент перед L1-нормой вектора весов листьев (по умолчанию 0).\n","# Гиперпараметр bagging_ fraction - задает случайный отбор наблюдений без возвращения.\n","# Он может принимать значения от 0 до 1\n","# Гиперпараметр feature_fraction - задает случайный отбор признаков для каждого дерева.\n","# Он может принимать значения от 0 до 1\n","\n","# создаем экземляр класса LGBMClassifier\n","lgbm_model2 = LGBMClassifier(random_state=42,\n","                             n_estimators=300,\n","                             learning_rate=0.01)\n","\n","# задаем сетку гиперпараметров\n","param_grid2 = {\n","    'lambda_l1': [0, 10],\n","    'bagging_fraction': [0.5, 1],\n","    'feature_fraction': [0.5, 1]\n","}\n","\n","# создаем экземпляр класса GridSearchCV, передав\n","# конвейер, сетку гиперпараметров и указав\n","# количество блоков перекрестной проверки\n","gs2 = GridSearchCV(lgbm_model2,\n","                   param_grid2,\n","                   scoring='roc_auc',\n","                   cv=5)\n","\n","# выполняем поиск по всем значениям сетки\n","gs2.fit(X_train, y_train)\n","\n","# смотрим наилучшие значения гиперпараметров\n","print('Наилучшие значения гиперпараметров: {}'.format(gs2.best_params_))\n","# смотрим наилучшее значение AUC\n","print('Наилучшее значение AUC: {:.3f}'.format(gs2.best_score_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jg4iSEwr5E-G","executionInfo":{"status":"ok","timestamp":1690537958859,"user_tz":-180,"elapsed":5410,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"505af842-5195-4323-8085-dd7daff57233"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","Наилучшие значения гиперпараметров: {'bagging_fraction': 0.5, 'feature_fraction': 1, 'lambda_l1': 10}\n","Наилучшее значение AUC: 0.844\n"]}]},{"cell_type":"code","source":["# Теперь вычислим важности признаков на основе информационного выигрыша.\n","\n","\n","# создаем экземляр класса LGBMClassifier\n","model_all_features = LGBMClassifier(\n","    random_state=42, learning_rate=0.01,\n","    n_estimators=300, bagging_fraction=0.5,\n","    feature_fraction=1, lambda_l1=10,\n","    importance_type='gain')\n","\n","# выполняем перекрестную проверку и сохраняем результат\n","# с помощью функции cross_validate()\n","output = cross_validate(\n","    model_all_features, X_train, y_train, cv=5,\n","    scoring='roc_auc', return_estimator=True)\n","\n","# создаем список fi, в который будем сохранять\n","# важности признаков, и сохраняем в него важности,\n","# рассчитанные для каждой из моделей\n","fi = []\n","for estimator in output['estimator']:\n","    fi.append(estimator.feature_importances_)\n","\n","# преобразовываем список в датафрейм, индексы в котором\n","# будут именами наших переменных\n","fi = pd.DataFrame(\n","    np.array(fi).T,\n","    columns=['importance ' + str(idx)\n","             for idx in range(len(fi))],\n","    index=X_train.columns)\n","# вычисляем усредненные важности и добавляем столбец с ними\n","fi['mean_importance'] = fi.mean(axis=1)\n","# смотрим полученный датафрейм\n","fi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"skBaEorB6n0h","executionInfo":{"status":"ok","timestamp":1690538064474,"user_tz":-180,"elapsed":660,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"8290b768-ba0d-41b4-887f-a89a2523c8b5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n"]},{"output_type":"execute_result","data":{"text/plain":["                          importance 0  importance 1  importance 2  \\\n","Pregnancies                 171.410934     26.784750    103.686310   \n","Glucose                    2674.974736   3464.012870   2776.149297   \n","BloodPressure                 0.000000      0.000000      0.916434   \n","SkinThickness                 0.000000      0.000000      0.000000   \n","Insulin                       4.358348     54.611050     16.258040   \n","BMI                        1000.592520   1000.114151   1418.376617   \n","DiabetesPedigreeFunction    105.774142     37.817805     60.334486   \n","Age                         629.178163   1144.303305    803.968171   \n","\n","                          importance 3  importance 4  mean_importance  \n","Pregnancies                 188.502132      3.432630        98.763351  \n","Glucose                    3458.806849   3260.360228      3126.860796  \n","BloodPressure                 0.000000      0.000000         0.183287  \n","SkinThickness                76.418138      0.000000        15.283628  \n","Insulin                     222.311633      0.000000        59.507814  \n","BMI                         840.794430   1191.530847      1090.281713  \n","DiabetesPedigreeFunction     12.148524     98.323883        62.879768  \n","Age                        1026.319534    916.123344       903.978504  "],"text/html":["\n","\n","  <div id=\"df-b2673c3b-4701-4809-818f-f3e39b8261ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>importance 0</th>\n","      <th>importance 1</th>\n","      <th>importance 2</th>\n","      <th>importance 3</th>\n","      <th>importance 4</th>\n","      <th>mean_importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Pregnancies</th>\n","      <td>171.410934</td>\n","      <td>26.784750</td>\n","      <td>103.686310</td>\n","      <td>188.502132</td>\n","      <td>3.432630</td>\n","      <td>98.763351</td>\n","    </tr>\n","    <tr>\n","      <th>Glucose</th>\n","      <td>2674.974736</td>\n","      <td>3464.012870</td>\n","      <td>2776.149297</td>\n","      <td>3458.806849</td>\n","      <td>3260.360228</td>\n","      <td>3126.860796</td>\n","    </tr>\n","    <tr>\n","      <th>BloodPressure</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.916434</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.183287</td>\n","    </tr>\n","    <tr>\n","      <th>SkinThickness</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>76.418138</td>\n","      <td>0.000000</td>\n","      <td>15.283628</td>\n","    </tr>\n","    <tr>\n","      <th>Insulin</th>\n","      <td>4.358348</td>\n","      <td>54.611050</td>\n","      <td>16.258040</td>\n","      <td>222.311633</td>\n","      <td>0.000000</td>\n","      <td>59.507814</td>\n","    </tr>\n","    <tr>\n","      <th>BMI</th>\n","      <td>1000.592520</td>\n","      <td>1000.114151</td>\n","      <td>1418.376617</td>\n","      <td>840.794430</td>\n","      <td>1191.530847</td>\n","      <td>1090.281713</td>\n","    </tr>\n","    <tr>\n","      <th>DiabetesPedigreeFunction</th>\n","      <td>105.774142</td>\n","      <td>37.817805</td>\n","      <td>60.334486</td>\n","      <td>12.148524</td>\n","      <td>98.323883</td>\n","      <td>62.879768</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>629.178163</td>\n","      <td>1144.303305</td>\n","      <td>803.968171</td>\n","      <td>1026.319534</td>\n","      <td>916.123344</td>\n","      <td>903.978504</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2673c3b-4701-4809-818f-f3e39b8261ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-5c5b4439-1346-417c-8bf5-fc3888689572\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c5b4439-1346-417c-8bf5-fc3888689572')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-5c5b4439-1346-417c-8bf5-fc3888689572 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2673c3b-4701-4809-818f-f3e39b8261ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2673c3b-4701-4809-818f-f3e39b8261ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Здесь мы видим, что некоторые признаки имеют нулевые или очень низкие важности.\n"],"metadata":{"id":"3-EZx6Az7HL4"}},{"cell_type":"code","source":["# записываем серию, в которой индексные метки - признаки,\n","# значения - важности\n","features = fi['mean_importance']\n","# сортируем индексные метки по возрастанию важностей\n","features = features.sort_values(ascending=True)\n","features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClyLP1v47Uq9","executionInfo":{"status":"ok","timestamp":1690538175258,"user_tz":-180,"elapsed":255,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"459ac344-2d0f-485c-b88a-cba20d7ed489"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BloodPressure                  0.183287\n","SkinThickness                 15.283628\n","Insulin                       59.507814\n","DiabetesPedigreeFunction      62.879768\n","Pregnancies                   98.763351\n","Age                          903.978504\n","BMI                         1090.281713\n","Glucose                     3126.860796\n","Name: mean_importance, dtype: float64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# выводим график усредненных важностей\n","features.plot.barh(figsize=(5, 10));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":830},"id":"fQVgEGxR7aX0","executionInfo":{"status":"ok","timestamp":1690538212785,"user_tz":-180,"elapsed":715,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"56ed95df-c3a8-4c3a-9535-a0bf0c484dc4"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x1000 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# создаем список признаков\n","features = list(features.index)\n","features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6w6x15Y7hQL","executionInfo":{"status":"ok","timestamp":1690538230742,"user_tz":-180,"elapsed":386,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"169038c1-cb9b-4129-ad1b-a7b14af75e55"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['BloodPressure',\n"," 'SkinThickness',\n"," 'Insulin',\n"," 'DiabetesPedigreeFunction',\n"," 'Pregnancies',\n"," 'Age',\n"," 'BMI',\n"," 'Glucose']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# вычисляем оценку AUC-ROC, усредненную по 5 проверочным\n","# блокам перекрестной проверки (5 моделям со всеми\n","# признаками)\n","auc_score_all = output['test_score'].mean()\n","auc_score_all"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KIcJWhS7p7J","executionInfo":{"status":"ok","timestamp":1690538258271,"user_tz":-180,"elapsed":15,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"071bffa4-6897-4fc9-812e-4f73e6ed5be6"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8444083033671135"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# задаем пороговое значение разницы AUC\n","tol = 0.0001\n","\n","print(\"выполнение последовательного удаления признаков\")\n","\n","# создаем список, в который будем\n","# записывать удаляемые признаки\n","features_to_remove = []\n","# создаем список, в который будем\n","# записывать значение AUC\n","auc_score_mean_list = []\n","# создаем список, в который будем\n","# записывать разницу AUC\n","diff_auc_list = []\n","\n","# задаем счетчик для оценки прогресса\n","count = 1\n","\n","# итерируем по всем признакам, признаки упорядочены по\n","# возрастанию важности на основе информационного выигрыша\n","for feature in features:\n","    print()\n","    print(\"проверяемый признак: \", feature, \" признак \", count,\n","          \" из \", len(features))\n","    count = count + 1\n","\n","    # создаем экземляр класса LGBMClassifier\n","    model = LGBMClassifier(\n","        random_state=42, learning_rate=0.01,\n","        n_estimators=300, bagging_fraction=0.5,\n","        feature_fraction=1, lambda_l1=10)\n","\n","    # обучаем модели со всеми признаками минус уже удаленные признаки\n","    # (берем их из списка удаляемых признаков) и оцениваемый признак\n","    auc_scores = cross_val_score(\n","        model,\n","        X_train.drop(features_to_remove + [feature], axis=1),\n","        y_train,\n","        scoring='roc_auc',\n","        cv=5)\n"," # вычисляем AUC, усредненный по проверочным блокам\n","    # перекрестной проверки\n","    auc_score_mean = auc_scores.mean()\n","\n","    # печатаем усредненное значение AUC\n","    print(\"AUC модели после удаления={}\".format((auc_score_mean)))\n","\n","    # добавляем усредненное значение AUC в список\n","    auc_score_mean_list.append(auc_score_mean)\n","\n","    # печатаем AUC модели со всеми признаками\n","    # (опорное значение AUC)\n","    print(\"AUC модели со всеми признаками={}\".format((auc_score_all)))\n","\n","    # определяем разницу AUC (если отрицательное значение\n","    # - удаление признака улучшило AUC)\n","    diff_auc = auc_score_all - auc_score_mean\n","\n","    # записываем разницу AUC в список\n","    diff_auc_list.append(diff_auc)\n","\n","    # сравниваем разницу AUC с порогом, заданным заранее\n","    # если разница AUC больше или равна порогу, сохраняем\n","    if diff_auc >= tol:\n","        print(\"Разница AUC={}\".format(diff_auc))\n","        print(\"сохраняем: \", feature)\n","        print\n","\n","    # если разница AUC меньше порога, удаляем\n","    else:\n","        print(\"Разница AUC={}\".format(diff_auc))\n","        print(\"удаляем: \", feature)\n","        print\n","\n","        # если разница AUC меньше порога и мы удаляем признак,\n","        # мы в качестве нового опорного значения AUC задаем\n","        # значение AUC для модели с оставшимися признаками\n","        auc_score_all = auc_score_mean\n"," # добавляем удаляемый признак в список\n","        features_to_remove.append(feature)\n","\n","# формируем датафрейм\n","df = pd.DataFrame({'feature': features,\n","                   'auc_score_mean': auc_score_mean_list,\n","                   'diff_auc_score': diff_auc_list})\n","\n","# цикл завершен, вычисляем количество\n","# удаленных признаков\n","print(\"ВЫПОЛНЕНО!!\")\n","print(\"общее количество признаков для удаления: \",\n","      len(features_to_remove))\n","\n","# определяем признаки, которые мы хотим сохранить (не удаляем)\n","features_to_keep = [x for x in features\n","                    if x not in features_to_remove]\n","print(\"общее количество признаков для сохранения: \",\n","      len(features_to_keep))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c3LXnUz8P_j","executionInfo":{"status":"ok","timestamp":1690538445380,"user_tz":-180,"elapsed":2536,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"9961305a-5750-4f90-ae73-75299e6789bd"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["выполнение последовательного удаления признаков\n","\n","проверяемый признак:  BloodPressure  признак  1  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8444855234443336\n","AUC модели со всеми признаками=0.8444083033671135\n","Разница AUC=-7.722007722010815e-05\n","удаляем:  BloodPressure\n","\n","проверяемый признак:  SkinThickness  признак  2  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8449874539462641\n","AUC модели со всеми признаками=0.8444855234443336\n","Разница AUC=-0.0005019305019304809\n","удаляем:  SkinThickness\n","\n","проверяемый признак:  Insulin  признак  3  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8469992401685765\n","AUC модели со всеми признаками=0.8449874539462641\n","Разница AUC=-0.0020117862223124616\n","удаляем:  Insulin\n","\n","проверяемый признак:  DiabetesPedigreeFunction  признак  4  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.847998389039579\n","AUC модели со всеми признаками=0.8469992401685765\n","Разница AUC=-0.0009991488710024976\n","удаляем:  DiabetesPedigreeFunction\n","\n","проверяемый признак:  Pregnancies  признак  5  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8488229092119253\n","AUC модели со всеми признаками=0.847998389039579\n","Разница AUC=-0.0008245201723462436\n","удаляем:  Pregnancies\n","\n","проверяемый признак:  Age  признак  6  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8139183151768965\n","AUC модели со всеми признаками=0.8488229092119253\n","Разница AUC=0.03490459403502877\n","сохраняем:  Age\n","\n","проверяемый признак:  BMI  признак  7  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.8275806584616653\n","AUC модели со всеми признаками=0.8488229092119253\n","Разница AUC=0.021242250750259983\n","сохраняем:  BMI\n","\n","проверяемый признак:  Glucose  признак  8  из  8\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","AUC модели после удаления=0.77588314205019\n","AUC модели со всеми признаками=0.8488229092119253\n","Разница AUC=0.07293976716173523\n","сохраняем:  Glucose\n","ВЫПОЛНЕНО!!\n","общее количество признаков для удаления:  5\n","общее количество признаков для сохранения:  3\n"]}]},{"cell_type":"code","source":["dgg_new= []\n","for col in features_to_keep:\n","  dgg_new.append(data[col])\n","dff1 = pd.DataFrame(dgg_new).T\n","dff1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"9BukYu519Q5v","executionInfo":{"status":"ok","timestamp":1690539477073,"user_tz":-180,"elapsed":268,"user":{"displayName":"ольга кузнецова","userId":"04325811963451346545"}},"outputId":"5ade65f6-9587-4463-bab5-6b77fbcb9bfe"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Age   BMI  Glucose\n","0    50.0  33.6    148.0\n","1    31.0  26.6     85.0\n","2    32.0  23.3    183.0\n","3    21.0  28.1     89.0\n","4    33.0  43.1    137.0\n","..    ...   ...      ...\n","763  63.0  32.9    101.0\n","764  27.0  36.8    122.0\n","765  30.0  26.2    121.0\n","766  47.0  30.1    126.0\n","767  23.0  30.4     93.0\n","\n","[768 rows x 3 columns]"],"text/html":["\n","\n","  <div id=\"df-05375d2b-8ae6-4278-a1dd-cd3ede3e0847\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>BMI</th>\n","      <th>Glucose</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50.0</td>\n","      <td>33.6</td>\n","      <td>148.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>31.0</td>\n","      <td>26.6</td>\n","      <td>85.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>32.0</td>\n","      <td>23.3</td>\n","      <td>183.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21.0</td>\n","      <td>28.1</td>\n","      <td>89.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33.0</td>\n","      <td>43.1</td>\n","      <td>137.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>63.0</td>\n","      <td>32.9</td>\n","      <td>101.0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>27.0</td>\n","      <td>36.8</td>\n","      <td>122.0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>30.0</td>\n","      <td>26.2</td>\n","      <td>121.0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>47.0</td>\n","      <td>30.1</td>\n","      <td>126.0</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>23.0</td>\n","      <td>30.4</td>\n","      <td>93.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05375d2b-8ae6-4278-a1dd-cd3ede3e0847')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-8bd7e3b2-ca31-4910-8871-4901cc371195\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bd7e3b2-ca31-4910-8871-4901cc371195')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-8bd7e3b2-ca31-4910-8871-4901cc371195 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-05375d2b-8ae6-4278-a1dd-cd3ede3e0847 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-05375d2b-8ae6-4278-a1dd-cd3ede3e0847');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["**Отбор признаков – это тоже модель, либо использующая вычисление статистик признаков (в случае с методами-фильтрами), либо использующая параметры моделей машинного обучения (в случае с методами-обертками и встро- енными методами), поэтому модели отбора признаков строим на обучающей выборке, настраиваем гиперпараметры на проверочной выборке и получаем итоговую оценку качества на тестовой.**\n","\n"],"metadata":{"id":"j25ZBVSA10kr"}},{"cell_type":"markdown","source":["## Домашнее задание\n","\n","1. Загрузить выборку с сайта Kaggle.com.\n","2. Провести анализ полученной выборки.\n","3. Провести отбор информативных признаков используя два метода feature selection.\n"],"metadata":{"id":"DTeain-utVYI"}}]}